{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3165d534-6005-43a3-a1d7-853855d073e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/blastn_hadoop.alfa.20240612.214547.627843\n",
      "Running step 1 of 1...\n",
      "job output is in /tmp/blastn_hadoop.alfa.20240612.214547.627843/output\n",
      "Streaming final output from /tmp/blastn_hadoop.alfa.20240612.214547.627843/output...\n",
      "null\t[\"ENST00000535880.2\", 19.0, \"GTA-CGCATACGG-CATA\", \"GTACCGGATAAGGCCAGA\"]\n",
      "null\t[\"ENST00000390392.3\", 19.0, \"AG-TACGCATACGGCA\", \"AGTTACGCAGACACCA\"]\n",
      "null\t[\"ENST00000390427.3\", 19.0, \"TACGCATAC-GGCATA\", \"TACTTATACTGGTATA\"]\n",
      "Removing temp directory /tmp/blastn_hadoop.alfa.20240612.214547.627843...\n"
     ]
    }
   ],
   "source": [
    "# run mrjob locally\n",
    "!python3 blastn_hadoop.py --conf-path mrjob.conf seq_100.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b50beae-e0ce-40cc-ba03-efb37ba85dc1",
   "metadata": {},
   "source": [
    "for cdnas_100 \"AGTACGCATACGGCATA\"  \n",
    "null\t[\"ENST00000390427.3\", 19.0, \"TACGCATAC-GGCATA\", \"TACTTATACTGGTATA\"]  \n",
    "null\t[\"ENST00000390392.3\", 19.0, \"AG-TACGCATACGGCA\", \"AGTTACGCAGACACCA\"]  \n",
    "null\t[\"ENST00000535880.2\", 19.0, \"GTA-CGCATACGG-CATA\", \"GTACCGGATAAGGCCAGA\"]  \n",
    "func took: 49.2482 sec sec\n",
    "\n",
    "for cdnas_1000 \"AGTACGCATACGGCATA\"  \n",
    "null\t[\"ENST00000711113.1\", 23.0, \"AGTACGCATACGG\", \"AGTACGCATGCGG\"]  \n",
    "null\t[\"ENST00000711114.1\", 23.0, \"AGTACGCATACGG\", \"AGTACGCATGCGG\"]  \n",
    "null\t[\"ENST00000711115.1\", 23.0, \"AGTACGCATACGG\", \"AGTACGCATGCGG\"]  \n",
    "func took: 60.7836 sec\n",
    "\n",
    "for cdnas_10000 \"AGTACGCATACGGCATA\"  \n",
    "null\t[\"ENST00000245304.5\", 25.0, \"AGTACGCATA-C-GGCAT\", \"AGTACGAATATCTGGCAT\"]  \n",
    "func took: 390.8936 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c27fbb0-bfbd-4516-951a-5f269a6bda29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 3.3.6\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar\n",
      "Creating temp directory /tmp/blastn_hadoop.alfa.20240612.210757.296867\n",
      "uploading working dir files to hdfs:///user/alfa/tmp/mrjob/blastn_hadoop.alfa.20240612.210757.296867/files/wd...\n",
      "Copying other local files to hdfs:///user/alfa/tmp/mrjob/blastn_hadoop.alfa.20240612.210757.296867/files/\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [/tmp/hadoop-unjar7516736863640884886/] [] /tmp/streamjob6755667220132569857.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/alfa/.staging/job_1718224825310_0003\n",
      "  Total input files to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1718224825310_0003\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1718224825310_0003\n",
      "  The url to track the job: http://8b554f1da8b1:8088/proxy/application_1718224825310_0003/\n",
      "  Running job: job_1718224825310_0003\n",
      "  Job job_1718224825310_0003 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 3% reduce 0%\n",
      "   map 4% reduce 0%\n",
      "   map 5% reduce 0%\n",
      "   map 7% reduce 0%\n",
      "   map 8% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 10% reduce 0%\n",
      "   map 11% reduce 0%\n",
      "   map 12% reduce 0%\n",
      "   map 13% reduce 0%\n",
      "   map 15% reduce 0%\n",
      "   map 16% reduce 0%\n",
      "   map 17% reduce 0%\n",
      "   map 18% reduce 0%\n",
      "   map 19% reduce 0%\n",
      "   map 20% reduce 0%\n",
      "   map 22% reduce 0%\n",
      "   map 23% reduce 0%\n",
      "   map 24% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 26% reduce 0%\n",
      "   map 27% reduce 0%\n",
      "   map 29% reduce 0%\n",
      "   map 30% reduce 0%\n",
      "   map 31% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 33% reduce 0%\n",
      "   map 34% reduce 0%\n",
      "   map 35% reduce 0%\n",
      "   map 36% reduce 0%\n",
      "   map 38% reduce 0%\n",
      "   map 39% reduce 0%\n",
      "   map 40% reduce 0%\n",
      "   map 41% reduce 0%\n",
      "   map 43% reduce 0%\n",
      "   map 44% reduce 0%\n",
      "   map 45% reduce 0%\n",
      "   map 46% reduce 0%\n",
      "   map 47% reduce 0%\n",
      "   map 48% reduce 0%\n",
      "   map 49% reduce 0%\n",
      "   map 51% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 55% reduce 0%\n",
      "   map 56% reduce 0%\n",
      "   map 57% reduce 0%\n",
      "   map 58% reduce 0%\n",
      "   map 60% reduce 0%\n",
      "   map 61% reduce 0%\n",
      "   map 62% reduce 0%\n",
      "   map 63% reduce 0%\n",
      "   map 64% reduce 0%\n",
      "   map 65% reduce 0%\n",
      "   map 66% reduce 0%\n",
      "   map 83% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1718224825310_0003 completed successfully\n",
      "  Output directory: hdfs:///user/alfa/tmp/mrjob/blastn_hadoop.alfa.20240612.210757.296867/output\n",
      "Counters: 54\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=22434734\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=77\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2727\n",
      "\t\tFILE: Number of bytes written=850196\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=22434920\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=77\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=719019008\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=3094528\n",
      "\t\tTotal time spent by all map tasks (ms)=702167\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=702167\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3022\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=3022\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=702167\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3022\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=694350\n",
      "\t\tCombine input records=10000\n",
      "\t\tCombine output records=36\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=186\n",
      "\t\tInput split bytes=186\n",
      "\t\tMap input records=10000\n",
      "\t\tMap output bytes=738161\n",
      "\t\tMap output materialized bytes=2733\n",
      "\t\tMap output records=10000\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=369651712\n",
      "\t\tPeak Map Virtual memory (bytes)=3131998208\n",
      "\t\tPeak Reduce Physical memory (bytes)=277479424\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2576490496\n",
      "\t\tPhysical memory (bytes) snapshot=914432000\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce input records=36\n",
      "\t\tReduce output records=1\n",
      "\t\tReduce shuffle bytes=2733\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=72\n",
      "\t\tTotal committed heap usage (bytes)=962592768\n",
      "\t\tVirtual memory (bytes) snapshot=7717322752\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "job output is in hdfs:///user/alfa/tmp/mrjob/blastn_hadoop.alfa.20240612.210757.296867/output\n",
      "Streaming final output from hdfs:///user/alfa/tmp/mrjob/blastn_hadoop.alfa.20240612.210757.296867/output...\n",
      "null\t[\"ENST00000245304.5\", 25.0, \"AGTACGCATA-C-GGCAT\", \"AGTACGAATATCTGGCAT\"]\n",
      "Removing HDFS temp directory hdfs:///user/alfa/tmp/mrjob/blastn_hadoop.alfa.20240612.210757.296867...\n",
      "Removing temp directory /tmp/blastn_hadoop.alfa.20240612.210757.296867...\n",
      "func took: 390.8936 sec\n"
     ]
    }
   ],
   "source": [
    "# run mrjob in hadoop cluster\n",
    "from time import time\n",
    "\n",
    "ts = time() # Start timing the operation\n",
    "!python3 blastn_hadoop.py -r hadoop --conf-path mrjob.conf hdfs://localhost:9000/bigdata/cdnas_10000\n",
    "te = time() # End timing the operation\n",
    "print('func took: %2.4f sec' % (te-ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ffa775-5630-4395-a343-b6b5198e3a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

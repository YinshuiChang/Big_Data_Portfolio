{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3165d534-6005-43a3-a1d7-853855d073e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/blastn_hadoop.alfa.20240612.214547.627843\n",
      "Running step 1 of 1...\n",
      "job output is in /tmp/blastn_hadoop.alfa.20240612.214547.627843/output\n",
      "Streaming final output from /tmp/blastn_hadoop.alfa.20240612.214547.627843/output...\n",
      "null\t[\"ENST00000535880.2\", 19.0, \"GTA-CGCATACGG-CATA\", \"GTACCGGATAAGGCCAGA\"]\n",
      "null\t[\"ENST00000390392.3\", 19.0, \"AG-TACGCATACGGCA\", \"AGTTACGCAGACACCA\"]\n",
      "null\t[\"ENST00000390427.3\", 19.0, \"TACGCATAC-GGCATA\", \"TACTTATACTGGTATA\"]\n",
      "Removing temp directory /tmp/blastn_hadoop.alfa.20240612.214547.627843...\n"
     ]
    }
   ],
   "source": [
    "# run mrjob locally\n",
    "!python3 blastn_hadoop.py --conf-path mrjob.conf seq_100.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b50beae-e0ce-40cc-ba03-efb37ba85dc1",
   "metadata": {},
   "source": [
    "for cdnas_100 \"AGTACGCATACGGCATA\"  \n",
    "null\t[\"ENST00000390427.3\", 19.0, \"TACGCATAC-GGCATA\", \"TACTTATACTGGTATA\"]  \n",
    "null\t[\"ENST00000390392.3\", 19.0, \"AG-TACGCATACGGCA\", \"AGTTACGCAGACACCA\"]  \n",
    "null\t[\"ENST00000535880.2\", 19.0, \"GTA-CGCATACGG-CATA\", \"GTACCGGATAAGGCCAGA\"]  \n",
    "func took: 49.2482 sec sec\n",
    "\n",
    "for cdnas_1000 \"AGTACGCATACGGCATA\"  \n",
    "null\t[\"ENST00000711113.1\", 23.0, \"AGTACGCATACGG\", \"AGTACGCATGCGG\"]  \n",
    "null\t[\"ENST00000711114.1\", 23.0, \"AGTACGCATACGG\", \"AGTACGCATGCGG\"]  \n",
    "null\t[\"ENST00000711115.1\", 23.0, \"AGTACGCATACGG\", \"AGTACGCATGCGG\"]  \n",
    "func took: 60.7836 sec\n",
    "\n",
    "for cdnas_10000 \"AGTACGCATACGGCATA\"  \n",
    "null\t[\"ENST00000245304.5\", 25.0, \"AGTACGCATA-C-GGCAT\", \"AGTACGAATATCTGGCAT\"]  \n",
    "func took: 390.8936 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c27fbb0-bfbd-4516-951a-5f269a6bda29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 3.3.6\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar\n",
      "Creating temp directory /tmp/blastn_hadoop.alfa.20240613.232252.201183\n",
      "uploading working dir files to hdfs:///user/alfa/tmp/mrjob/blastn_hadoop.alfa.20240613.232252.201183/files/wd...\n",
      "Copying other local files to hdfs:///user/alfa/tmp/mrjob/blastn_hadoop.alfa.20240613.232252.201183/files/\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [/tmp/hadoop-unjar6320580389294973849/] [] /tmp/streamjob2304076358581752933.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/alfa/.staging/job_1718282157808_0003\n",
      "  Total input files to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1718282157808_0003\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1718282157808_0003\n",
      "  The url to track the job: http://8b554f1da8b1:8088/proxy/application_1718282157808_0003/\n",
      "  Running job: job_1718282157808_0003\n",
      "  Job job_1718282157808_0003 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1718282157808_0003 completed successfully\n",
      "  Output directory: hdfs:///user/alfa/tmp/mrjob/blastn_hadoop.alfa.20240613.232252.201183/output\n",
      "Counters: 55\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=57450\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=77\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=259\n",
      "\t\tFILE: Number of bytes written=845599\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=57632\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=77\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=13894656\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=3816448\n",
      "\t\tTotal time spent by all map tasks (ms)=13569\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=13569\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3727\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=3727\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=13569\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3727\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2110\n",
      "\t\tCombine input records=100\n",
      "\t\tCombine output records=3\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=180\n",
      "\t\tInput split bytes=182\n",
      "\t\tMap input records=100\n",
      "\t\tMap output bytes=6642\n",
      "\t\tMap output materialized bytes=265\n",
      "\t\tMap output records=100\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=322940928\n",
      "\t\tPeak Map Virtual memory (bytes)=2571780096\n",
      "\t\tPeak Reduce Physical memory (bytes)=227041280\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2575757312\n",
      "\t\tPhysical memory (bytes) snapshot=828170240\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce input records=3\n",
      "\t\tReduce output records=1\n",
      "\t\tReduce shuffle bytes=265\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=6\n",
      "\t\tTotal committed heap usage (bytes)=863502336\n",
      "\t\tVirtual memory (bytes) snapshot=7717990400\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "job output is in hdfs:///user/alfa/tmp/mrjob/blastn_hadoop.alfa.20240613.232252.201183/output\n",
      "Streaming final output from hdfs:///user/alfa/tmp/mrjob/blastn_hadoop.alfa.20240613.232252.201183/output...\n",
      "null\t[\"ENST00000542354.1\", 24.0, \"CCCTCTCTAGGGTTCTAT\", \"CCTTCTCTATGTTTCCAT\"]\n",
      "Removing HDFS temp directory hdfs:///user/alfa/tmp/mrjob/blastn_hadoop.alfa.20240613.232252.201183...\n",
      "Removing temp directory /tmp/blastn_hadoop.alfa.20240613.232252.201183...\n",
      "func took: 54.1228 sec\n"
     ]
    }
   ],
   "source": [
    "# run mrjob in hadoop cluster\n",
    "from time import time\n",
    "\n",
    "ts = time() # Start timing the operation\n",
    "!python3 blastn_hadoop.py -r hadoop --conf-path mrjob.conf --query_sequence CCCTCTCTAGGGTTCTATAG hdfs://localhost:9000/bigdata/cdnas_100\n",
    "te = time() # End timing the operation\n",
    "print('func took: %2.4f sec' % (te-ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ffa775-5630-4395-a343-b6b5198e3a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

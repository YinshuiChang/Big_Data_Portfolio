{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c420e8d1-56dd-467c-90dc-7f6789e57d87",
   "metadata": {},
   "source": [
    "For 10f x 10q func took: func took: 126.4940 sec\n",
    "\"ENST00000603077.1\"\t9\n",
    "\"ENST00000604446.1\"\t1\n",
    "\"ENST00000604642.1\"\t1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa0001c-4a0d-49e4-a297-5436580425f9",
   "metadata": {},
   "source": [
    "For 100f x 100q func took: 478.8154 sec\n",
    "\"ENST00000390353.2\"\t1\n",
    "\"ENST00000390357.3\"\t9\n",
    "\"ENST00000390360.3\"\t4\n",
    "\"ENST00000390361.3\"\t2\n",
    "\"ENST00000390362.1\"\t1\n",
    "\"ENST00000390363.2\"\t2\n",
    "\"ENST00000390381.3\"\t3\n",
    "\"ENST00000390387.3\"\t11\n",
    "\"ENST00000390392.3\"\t11\n",
    "\"ENST00000390423.2\"\t3\n",
    "\"ENST00000390424.2\"\t4\n",
    "\"ENST00000390425.2\"\t5\n",
    "\"ENST00000390426.2\"\t2\n",
    "\"ENST00000390427.3\"\t6\n",
    "\"ENST00000390469.2\"\t2\n",
    "\"ENST00000455382.2\"\t3\n",
    "\"ENST00000535880.2\"\t1\n",
    "\"ENST00000542354.1\"\t1\n",
    "\"ENST00000547918.2\"\t1\n",
    "\"ENST00000631824.1\"\t4\n",
    "\"ENST00000632187.1\"\t3\n",
    "\"ENST00000632248.1\"\t3\n",
    "\"ENST00000632308.1\"\t1\n",
    "\"ENST00000633265.1\"\t1\n",
    "\"ENST00000633313.1\"\t1\n",
    "\"ENST00000634111.1\"\t6\n",
    "\"ENST00000634176.1\"\t2\n",
    "\"ENST00000634383.1\"\t6\n",
    "\"ENST00000634605.1\"\t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d58ea3a-209f-471c-82f7-a392e91bf1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 3.3.6\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar\n",
      "Creating temp directory /tmp/alignment_hadoop.alfa.20240613.104233.053447\n",
      "uploading working dir files to hdfs:///user/alfa/tmp/mrjob/alignment_hadoop.alfa.20240613.104233.053447/files/wd...\n",
      "Copying other local files to hdfs:///user/alfa/tmp/mrjob/alignment_hadoop.alfa.20240613.104233.053447/files/\n",
      "Running step 1 of 3...\n",
      "  packageJobJar: [/tmp/hadoop-unjar94011217564985525/] [] /tmp/streamjob2669565713195442554.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/alfa/.staging/job_1718267087421_0056\n",
      "  Total input files to process : 2\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1718267087421_0056\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1718267087421_0056\n",
      "  The url to track the job: http://8b554f1da8b1:8088/proxy/application_1718267087421_0056/\n",
      "  Running job: job_1718267087421_0056\n",
      "  Job job_1718267087421_0056 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 50% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1718267087421_0056 completed successfully\n",
      "  Output directory: hdfs:///user/alfa/tmp/mrjob/alignment_hadoop.alfa.20240613.104233.053447/step-output/0000\n",
      "Counters: 54\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=109532\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=10953400\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=111740\n",
      "\t\tFILE: Number of bytes written=1067234\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=109718\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=10953400\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=12418048\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=5618688\n",
      "\t\tTotal time spent by all map tasks (ms)=12127\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=12127\n",
      "\t\tTotal time spent by all reduce tasks (ms)=5487\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=5487\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=12127\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=5487\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=3900\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=269\n",
      "\t\tInput split bytes=186\n",
      "\t\tMap input records=200\n",
      "\t\tMap output bytes=110934\n",
      "\t\tMap output materialized bytes=111746\n",
      "\t\tMap output records=200\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=279703552\n",
      "\t\tPeak Map Virtual memory (bytes)=2571137024\n",
      "\t\tPeak Reduce Physical memory (bytes)=234532864\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2578141184\n",
      "\t\tPhysical memory (bytes) snapshot=787836928\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce input records=200\n",
      "\t\tReduce output records=10000\n",
      "\t\tReduce shuffle bytes=111746\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=400\n",
      "\t\tTotal committed heap usage (bytes)=875036672\n",
      "\t\tVirtual memory (bytes) snapshot=7720366080\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Running step 2 of 3...\n",
      "  packageJobJar: [/tmp/hadoop-unjar1104560781292722478/] [] /tmp/streamjob115685011875289667.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/alfa/.staging/job_1718267087421_0057\n",
      "  Total input files to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1718267087421_0057\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1718267087421_0057\n",
      "  The url to track the job: http://8b554f1da8b1:8088/proxy/application_1718267087421_0057/\n",
      "  Running job: job_1718267087421_0057\n",
      "  Job job_1718267087421_0057 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 9% reduce 0%\n",
      "   map 14% reduce 0%\n",
      "   map 20% reduce 0%\n",
      "   map 25% reduce 0%\n",
      "   map 32% reduce 0%\n",
      "   map 53% reduce 0%\n",
      "   map 54% reduce 0%\n",
      "   map 54% reduce 17%\n",
      "   map 55% reduce 17%\n",
      "   map 56% reduce 17%\n",
      "   map 57% reduce 17%\n",
      "   map 58% reduce 17%\n",
      "   map 59% reduce 17%\n",
      "   map 60% reduce 17%\n",
      "   map 61% reduce 17%\n",
      "   map 62% reduce 17%\n",
      "   map 63% reduce 17%\n",
      "   map 64% reduce 17%\n",
      "   map 65% reduce 17%\n",
      "   map 66% reduce 17%\n",
      "   map 67% reduce 17%\n",
      "   map 68% reduce 17%\n",
      "   map 69% reduce 17%\n",
      "   map 70% reduce 17%\n",
      "   map 71% reduce 17%\n",
      "   map 72% reduce 17%\n",
      "   map 73% reduce 17%\n",
      "   map 74% reduce 17%\n",
      "   map 75% reduce 17%\n",
      "   map 78% reduce 17%\n",
      "   map 83% reduce 17%\n",
      "   map 100% reduce 17%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1718267087421_0057 completed successfully\n",
      "  Output directory: hdfs:///user/alfa/tmp/mrjob/alignment_hadoop.alfa.20240613.104233.053447/step-output/0001\n",
      "Counters: 55\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=10957496\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=5100\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1623093\n",
      "\t\tFILE: Number of bytes written=4089949\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=10957828\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=5100\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=3\n",
      "\t\tKilled map tasks=1\n",
      "\t\tLaunched map tasks=3\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=757692416\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=335335424\n",
      "\t\tTotal time spent by all map tasks (ms)=739934\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=739934\n",
      "\t\tTotal time spent by all reduce tasks (ms)=327476\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=327476\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=739934\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=327476\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=409640\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=391\n",
      "\t\tInput split bytes=332\n",
      "\t\tMap input records=10000\n",
      "\t\tMap output bytes=1599900\n",
      "\t\tMap output materialized bytes=1623099\n",
      "\t\tMap output records=10000\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=407494656\n",
      "\t\tPeak Map Virtual memory (bytes)=3125039104\n",
      "\t\tPeak Reduce Physical memory (bytes)=238575616\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2575708160\n",
      "\t\tPhysical memory (bytes) snapshot=861691904\n",
      "\t\tReduce input groups=98\n",
      "\t\tReduce input records=10000\n",
      "\t\tReduce output records=100\n",
      "\t\tReduce shuffle bytes=1623099\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=20000\n",
      "\t\tTotal committed heap usage (bytes)=905445376\n",
      "\t\tVirtual memory (bytes) snapshot=7714263040\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "Running step 3 of 3...\n",
      "  packageJobJar: [/tmp/hadoop-unjar4682916904650438576/] [] /tmp/streamjob3706427733813059890.jar tmpDir=null\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Connecting to ResourceManager at /0.0.0.0:8032\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/alfa/.staging/job_1718267087421_0058\n",
      "  Total input files to process : 1\n",
      "  number of splits:2\n",
      "  Submitting tokens for job: job_1718267087421_0058\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1718267087421_0058\n",
      "  The url to track the job: http://8b554f1da8b1:8088/proxy/application_1718267087421_0058/\n",
      "  Running job: job_1718267087421_0058\n",
      "  Job job_1718267087421_0058 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1718267087421_0058 completed successfully\n",
      "  Output directory: hdfs:///user/alfa/tmp/mrjob/alignment_hadoop.alfa.20240613.104233.053447/output\n",
      "Counters: 54\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=7650\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=640\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5306\n",
      "\t\tFILE: Number of bytes written=854097\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=7982\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=640\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=8880128\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=4366336\n",
      "\t\tTotal time spent by all map tasks (ms)=8672\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=8672\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4264\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=4264\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=8672\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=4264\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=2640\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=332\n",
      "\t\tInput split bytes=332\n",
      "\t\tMap input records=100\n",
      "\t\tMap output bytes=5100\n",
      "\t\tMap output materialized bytes=5312\n",
      "\t\tMap output records=100\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=279777280\n",
      "\t\tPeak Map Virtual memory (bytes)=2572161024\n",
      "\t\tPeak Reduce Physical memory (bytes)=235814912\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2576556032\n",
      "\t\tPhysical memory (bytes) snapshot=790945792\n",
      "\t\tReduce input groups=29\n",
      "\t\tReduce input records=100\n",
      "\t\tReduce output records=29\n",
      "\t\tReduce shuffle bytes=5312\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=200\n",
      "\t\tTotal committed heap usage (bytes)=886571008\n",
      "\t\tVirtual memory (bytes) snapshot=7720574976\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "job output is in hdfs:///user/alfa/tmp/mrjob/alignment_hadoop.alfa.20240613.104233.053447/output\n",
      "Streaming final output from hdfs:///user/alfa/tmp/mrjob/alignment_hadoop.alfa.20240613.104233.053447/output...\n",
      "\"ENST00000390353.2\"\t1\n",
      "\"ENST00000390357.3\"\t9\n",
      "\"ENST00000390360.3\"\t4\n",
      "\"ENST00000390361.3\"\t2\n",
      "\"ENST00000390362.1\"\t1\n",
      "\"ENST00000390363.2\"\t2\n",
      "\"ENST00000390381.3\"\t3\n",
      "\"ENST00000390387.3\"\t11\n",
      "\"ENST00000390392.3\"\t11\n",
      "\"ENST00000390423.2\"\t3\n",
      "\"ENST00000390424.2\"\t4\n",
      "\"ENST00000390425.2\"\t5\n",
      "\"ENST00000390426.2\"\t2\n",
      "\"ENST00000390427.3\"\t6\n",
      "\"ENST00000390469.2\"\t2\n",
      "\"ENST00000455382.2\"\t3\n",
      "\"ENST00000535880.2\"\t1\n",
      "\"ENST00000542354.1\"\t1\n",
      "\"ENST00000547918.2\"\t1\n",
      "\"ENST00000631824.1\"\t4\n",
      "\"ENST00000632187.1\"\t3\n",
      "\"ENST00000632248.1\"\t3\n",
      "\"ENST00000632308.1\"\t1\n",
      "\"ENST00000633265.1\"\t1\n",
      "\"ENST00000633313.1\"\t1\n",
      "\"ENST00000634111.1\"\t6\n",
      "\"ENST00000634176.1\"\t2\n",
      "\"ENST00000634383.1\"\t6\n",
      "\"ENST00000634605.1\"\t1\n",
      "Removing HDFS temp directory hdfs:///user/alfa/tmp/mrjob/alignment_hadoop.alfa.20240613.104233.053447...\n",
      "Removing temp directory /tmp/alignment_hadoop.alfa.20240613.104233.053447...\n",
      "func took: 478.8154 sec\n"
     ]
    }
   ],
   "source": [
    "# run mrjob in hadoop cluster\n",
    "from time import time\n",
    "\n",
    "ts = time() # Start timing the operation\n",
    "!python3 alignment_hadoop.py -r hadoop --conf-path mrjob.conf hdfs://localhost:9000/bigdata/sequences_100 hdfs://localhost:9000/bigdata/cdnas_100\n",
    "te = time() # End timing the operation\n",
    "print('func took: %2.4f sec' % (te-ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d71d4-e21c-40d4-8f12-a9112c3696da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
